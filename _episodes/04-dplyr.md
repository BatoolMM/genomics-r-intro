---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 04-dplyr.md in _episodes_rmd/
title: "Aggregating and Analyzing Data with dplyr"
teaching: 40
exercises: 15
questions:
- "How can I manipulate dataframes without repeating myself?"
objectives:
- "Describe what the `dplyr` package in R is used for."
- "Apply common `dplyr` functions to manipulate data in R."
- "Employ the â€˜pipeâ€™ operator to link together a sequence of functions."
- "Employ the â€˜mutateâ€™ function to apply other chosen functions to existing columns and create new columns of data."
- "Employ the â€˜split-apply-combineâ€™ concept to split the data into groups, apply analysis to each group, and combine the results."

keypoints:
- "Use the `dplyr` package to manipulate dataframes."
- "Use `select()` to choose variables from a dataframe."
- "Use `filter()` to choose data based on values."
- "Use `mutate()` to create new variables."
- "Use `group_by()` and `summarize()` to work with subsets of data."

source: Rmd
---





Bracket subsetting is handy, but it can be cumbersome and difficult to read, especially for complicated operations. 

Luckily, the [`dplyr`](https://cran.r-project.org/package=dplyr)
package provides a number of very useful functions for manipulating data frames
in a way that will reduce repetition, reduce the probability of making
errors, and probably even save you some typing. As an added bonus, you might
even find the `dplyr` grammar easier to read.

Here we're going to cover 6 of the most commonly used functions as well as using
pipes (`%>%`) to combine them.

1. `select()`
2. `filter()`
3. `group_by()`
4. `summarize()`
5. `mutate()`

Packages in R are sets of additional functions that let you do more
stuff in R. The functions we've been using, like `str()`, come built into R;
packages give you access to more functions. You need to install a package and
then load it to be able to use it.


~~~
install.packages("dplyr") ## install
~~~
{: .language-r}

You might get asked to choose a CRAN mirror -- this is asking you to
choose a site to download the package from. The choice doesn't matter too much; I'd recommend choosing the RStudio mirror.


~~~
library("dplyr")          ## load
~~~
{: .language-r}

You only need to install a package once per computer, but you need to load it
every time you open a new R session and want to use that package.

## What is dplyr?

The package `dplyr` is a fairly new (2014) package that tries to provide easy
tools for the most common data manipulation tasks. It is built to work directly
with data frames. The thinking behind it was largely inspired by the package
`plyr` which has been in use for some time but suffered from being slow in some
cases.` dplyr` addresses this by porting much of the computation to C++. An
additional feature is the ability to work with data stored directly in an
external database. The benefits of doing this are that the data can be managed
natively in a relational database, queries can be conducted on that database,
and only the results of the query returned.

This addresses a common problem with R in that all operations are conducted in
memory and thus the amount of data you can work with is limited by available
memory. The database connections essentially remove that limitation in that you
can have a database of many 100s GB, conduct queries on it directly and pull
back just what you need for analysis in R.

### Selecting columns and filtering rows

To select columns of a
data frame, use `select()`. The first argument to this function is the data
frame (`variants`), and the subsequent arguments are the columns to keep.


~~~
select(variants, sample_id, REF, ALT, DP)
~~~
{: .language-r}

~~~
[90m# A tibble: 6 x 4[39m
  sample_id  REF      ALT          DP
  [3m[90m<chr>[39m[23m      [3m[90m<chr>[39m[23m    [3m[90m<chr>[39m[23m     [3m[90m<dbl>[39m[23m
[90m1[39m SRR2584863 T        G             4
[90m2[39m SRR2584863 G        T             6
[90m3[39m SRR2584863 G        T            10
[90m4[39m SRR2584863 CTTTTTTT CTTTTTTTT    12
[90m5[39m SRR2584863 CCGC     CCGCGC       10
[90m6[39m SRR2584863 C        T            10
~~~
{: .output}

To select all columns *except* certain ones, put a "-" in front of
the variable to exclude it.


~~~
select(variants, -CHROM)
~~~
{: .language-r}


~~~
[90m# A tibble: 6 x 28[39m
  sample_id    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP    VDB
  [3m[90m<chr>[39m[23m      [3m[90m<dbl>[39m[23m [3m[90m<lgl>[39m[23m [3m[90m<chr>[39m[23m [3m[90m<chr>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<lgl>[39m[23m  [3m[90m<lgl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m  [3m[90m<dbl>[39m[23m
[90m1[39m SRR25848â€¦   [4m9[24m972 [31mNA[39m    T     G        91 [31mNA[39m     FALSE    [31mNA[39m  [31mNA[39m       4 0.025[4m7[24m
[90m2[39m SRR25848â€¦ [4m2[24m[4m6[24m[4m3[24m235 [31mNA[39m    G     T        85 [31mNA[39m     FALSE    [31mNA[39m  [31mNA[39m       6 0.096[4m1[24m
[90m3[39m SRR25848â€¦ [4m2[24m[4m8[24m[4m1[24m923 [31mNA[39m    G     T       217 [31mNA[39m     FALSE    [31mNA[39m  [31mNA[39m      10 0.774 
[90m4[39m SRR25848â€¦ [4m4[24m[4m3[24m[4m3[24m359 [31mNA[39m    CTTTâ€¦ CTTTâ€¦    64 [31mNA[39m     TRUE     12   1      12 0.478 
[90m5[39m SRR25848â€¦ [4m4[24m[4m7[24m[4m3[24m901 [31mNA[39m    CCGC  CCGCâ€¦   228 [31mNA[39m     TRUE      9   0.9    10 0.660 
[90m6[39m SRR25848â€¦ [4m6[24m[4m4[24m[4m8[24m692 [31mNA[39m    C     T       210 [31mNA[39m     FALSE    [31mNA[39m  [31mNA[39m      10 0.268 
[90m# â€¦ with 16 more variables: RPB [3m[90m<dbl>[90m[23m, MQB [3m[90m<dbl>[90m[23m, BQB [3m[90m<dbl>[90m[23m, MQSB [3m[90m<dbl>[90m[23m,[39m
[90m#   SGB [3m[90m<dbl>[90m[23m, MQ0F [3m[90m<dbl>[90m[23m, ICB [3m[90m<lgl>[90m[23m, HOB [3m[90m<lgl>[90m[23m, AC [3m[90m<dbl>[90m[23m, AN [3m[90m<dbl>[90m[23m, DP4 [3m[90m<chr>[90m[23m,[39m
[90m#   MQ [3m[90m<dbl>[90m[23m, Indiv [3m[90m<chr>[90m[23m, gt_PL [3m[90m<dbl>[90m[23m, gt_GT [3m[90m<dbl>[90m[23m, gt_GT_alleles [3m[90m<chr>[90m[23m[39m
~~~
{: .output}

To choose rows, use `filter()`:


~~~
filter(variants, sample_id == "SRR2584863")
~~~
{: .language-r}


~~~
[90m# A tibble: 6 x 29[39m
  sample_id CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP
  [3m[90m<chr>[39m[23m     [3m[90m<chr>[39m[23m  [3m[90m<dbl>[39m[23m [3m[90m<lgl>[39m[23m [3m[90m<chr>[39m[23m [3m[90m<chr>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<lgl>[39m[23m  [3m[90m<lgl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m
[90m1[39m SRR25848â€¦ CP00â€¦   [4m9[24m972 [31mNA[39m    T     G        91 [31mNA[39m     FALSE    [31mNA[39m  [31mNA[39m       4
[90m2[39m SRR25848â€¦ CP00â€¦ [4m2[24m[4m6[24m[4m3[24m235 [31mNA[39m    G     T        85 [31mNA[39m     FALSE    [31mNA[39m  [31mNA[39m       6
[90m3[39m SRR25848â€¦ CP00â€¦ [4m2[24m[4m8[24m[4m1[24m923 [31mNA[39m    G     T       217 [31mNA[39m     FALSE    [31mNA[39m  [31mNA[39m      10
[90m4[39m SRR25848â€¦ CP00â€¦ [4m4[24m[4m3[24m[4m3[24m359 [31mNA[39m    CTTTâ€¦ CTTTâ€¦    64 [31mNA[39m     TRUE     12   1      12
[90m5[39m SRR25848â€¦ CP00â€¦ [4m4[24m[4m7[24m[4m3[24m901 [31mNA[39m    CCGC  CCGCâ€¦   228 [31mNA[39m     TRUE      9   0.9    10
[90m6[39m SRR25848â€¦ CP00â€¦ [4m6[24m[4m4[24m[4m8[24m692 [31mNA[39m    C     T       210 [31mNA[39m     FALSE    [31mNA[39m  [31mNA[39m      10
[90m# â€¦ with 17 more variables: VDB [3m[90m<dbl>[90m[23m, RPB [3m[90m<dbl>[90m[23m, MQB [3m[90m<dbl>[90m[23m, BQB [3m[90m<dbl>[90m[23m,[39m
[90m#   MQSB [3m[90m<dbl>[90m[23m, SGB [3m[90m<dbl>[90m[23m, MQ0F [3m[90m<dbl>[90m[23m, ICB [3m[90m<lgl>[90m[23m, HOB [3m[90m<lgl>[90m[23m, AC [3m[90m<dbl>[90m[23m,[39m
[90m#   AN [3m[90m<dbl>[90m[23m, DP4 [3m[90m<chr>[90m[23m, MQ [3m[90m<dbl>[90m[23m, Indiv [3m[90m<chr>[90m[23m, gt_PL [3m[90m<dbl>[90m[23m, gt_GT [3m[90m<dbl>[90m[23m,[39m
[90m#   gt_GT_alleles [3m[90m<chr>[90m[23m[39m
~~~
{: .output}

Note that this is equivalent to the base R code below, 
but is easier to read!


~~~
variants[variants$sample_id == "SRR2584863",]
~~~
{: .language-r}

### Pipes

But what if you wanted to select and filter? We can do this with pipes. Pipes, are a fairly recent addition to R. Pipes let you
take the output of one function and send it directly to the next, which is
useful when you need to many things to the same data set. It was
possible to do this before pipes were added to R, but it was 
much messier and more difficult. Pipes in R look like
`%>%` and are made available via the `magrittr` package, which is installed as
part of `dplyr`. If you use RStudio, you can type the pipe with
<kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>M</kbd> if you're using a PC,
or <kbd>Cmd</kbd> + <kbd>Shift</kbd> + <kbd>M</kbd> if you're using a Mac.


~~~
variants %>%
  filter(sample_id == "SRR2584863") %>%
  select(REF, ALT, DP) %>%
  head()
~~~
{: .language-r}



~~~
[90m# A tibble: 6 x 3[39m
  REF      ALT          DP
  [3m[90m<chr>[39m[23m    [3m[90m<chr>[39m[23m     [3m[90m<dbl>[39m[23m
[90m1[39m T        G             4
[90m2[39m G        T             6
[90m3[39m G        T            10
[90m4[39m CTTTTTTT CTTTTTTTT    12
[90m5[39m CCGC     CCGCGC       10
[90m6[39m C        T            10
~~~
{: .output}

In the above code, we use the pipe to send the `variants` dataset first through
`filter()`, to keep rows where `sample_id` matches a particular sample, and then through `select()` to
keep only the `REF`, `ALT`, and `DP` columns. Since `%>%` takes
the object on its left and passes it as the first argument to the function on
its right, we don't need to explicitly include the data frame as an argument
to the `filter()` and `select()` functions any more. We then pipe the results
to the `head()` function so that we only see the first six rows of data.

Some may find it helpful to read the pipe like the word "then". For instance,
in the above example, we took the data frame `variants`, *then* we `filter`ed
for rows where `sample_id` was SRR2584863, *then* we `select`ed the `REF`, `ALT`, and `DP` columns, *then* we showed only the first six rows. 
The **`dplyr`** functions by themselves are somewhat simple,
but by combining them into linear workflows with the pipe, we can accomplish
more complex manipulations of data frames.

If we want to create a new object with this smaller version of the data we
can do so by assigning it a new name:


~~~
SRR2584863_variants <- variants %>%
  filter(sample_id == "SRR2584863") %>%
  select(REF, ALT, DP)
~~~
{: .language-r}

This new object includes all of the data from this sample. Let's look at just
the first six rows to confirm it's what we want:


~~~
SRR2584863_variants %>% head()
~~~
{: .language-r}



~~~
[90m# A tibble: 6 x 3[39m
  REF      ALT          DP
  [3m[90m<chr>[39m[23m    [3m[90m<chr>[39m[23m     [3m[90m<dbl>[39m[23m
[90m1[39m T        G             4
[90m2[39m G        T             6
[90m3[39m G        T            10
[90m4[39m CTTTTTTT CTTTTTTTT    12
[90m5[39m CCGC     CCGCGC       10
[90m6[39m C        T            10
~~~
{: .output}
We can also look at the first six rows using tidyverse function `slice()`:


~~~
SRR2584863_variants %>% slice(1:6)
~~~
{: .language-r}



~~~
[90m# A tibble: 6 x 3[39m
  REF      ALT          DP
  [3m[90m<chr>[39m[23m    [3m[90m<chr>[39m[23m     [3m[90m<dbl>[39m[23m
[90m1[39m T        G             4
[90m2[39m G        T             6
[90m3[39m G        T            10
[90m4[39m CTTTTTTT CTTTTTTTT    12
[90m5[39m CCGC     CCGCGC       10
[90m6[39m C        T            10
~~~
{: .output}

> ## Exercise: Pipe and filter
>
> Starting with the `variants` dataframe, use pipes to subset the data
> to include only observations from SRR2584863 sample,
> where the filtered
> depth (DP) is at least 10. Retain only the columns `REF`, `ALT`, 
> and `POS`.
>
>> ## Solution
>> 
>> ~~~
>>  variants %>%   
>>  filter(sample_id == "SRR2584863" & DP >= 10) %>%
>>  select(REF, ALT, POS)
>> ~~~
>> {: .language-r}
>> 
>> 
>> 
>> ~~~
>> [90m# A tibble: 16 x 3[39m
>>    REF      ALT           POS
>>    [3m[90m<chr>[39m[23m    [3m[90m<chr>[39m[23m       [3m[90m<dbl>[39m[23m
>> [90m 1[39m G        T          [4m2[24m[4m8[24m[4m1[24m923
>> [90m 2[39m CTTTTTTT CTTTTTTTT  [4m4[24m[4m3[24m[4m3[24m359
>> [90m 3[39m CCGC     CCGCGC     [4m4[24m[4m7[24m[4m3[24m901
>> [90m 4[39m C        T          [4m6[24m[4m4[24m[4m8[24m692
>> [90m 5[39m G        A         1[4m7[24m[4m3[24m[4m3[24m343
>> [90m 6[39m A        C         2[4m4[24m[4m4[24m[4m6[24m984
>> [90m 7[39m G        T         2[4m6[24m[4m1[24m[4m8[24m472
>> [90m 8[39m A        T         2[4m6[24m[4m6[24m[4m5[24m639
>> [90m 9[39m G        A         2[4m9[24m[4m9[24m[4m9[24m330
>> [90m10[39m A        C         3[4m3[24m[4m3[24m[4m9[24m313
>> [90m11[39m C        A         3[4m4[24m[4m0[24m[4m1[24m754
>> [90m12[39m A        C         3[4m4[24m[4m8[24m[4m8[24m669
>> [90m13[39m G        T         3[4m9[24m[4m0[24m[4m9[24m807
>> [90m14[39m A        G         4[4m1[24m[4m0[24m[4m0[24m183
>> [90m15[39m A        C         4[4m2[24m[4m0[24m[4m1[24m958
>> [90m16[39m TGG      T         4[4m4[24m[4m3[24m[4m1[24m393
>> ~~~
>> {: .output}
> {: .solution}
{: .challenge}

### Mutate

Frequently you'll want to create new columns based on the values in existing
columns, for example to do unit conversions or find the ratio of values in two
columns. For this we'll use the `dplyr` function `mutate()`.

We have a column titled "QUAL". This is a Phred-scaled confidence
score that a polymorphism exists at this position given the sequencing
data. Lower QUAL scores indicate low probability of a polymorphism
existing at that site. We can convert the confidence value QUAL
to a probability value according to the formula:

Probability = 1- 10 ^ -(QUAL/10)

Let's add a column (`POLPROB`) to our `variants` dataframe that shows 
the probability of a polymorphism at that site given the data. We'll show 
only the first six rows of data.


~~~
variants %>%
  mutate(POLPROB = 1 - (10 ^ -(QUAL/10))) %>%
  slice(1:6)
~~~
{: .language-r}



~~~
[90m# A tibble: 6 x 30[39m
  sample_id CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP
  [3m[90m<chr>[39m[23m     [3m[90m<chr>[39m[23m  [3m[90m<dbl>[39m[23m [3m[90m<lgl>[39m[23m [3m[90m<chr>[39m[23m [3m[90m<chr>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<lgl>[39m[23m  [3m[90m<lgl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m
[90m1[39m SRR25848â€¦ CP00â€¦   [4m9[24m972 [31mNA[39m    T     G        91 [31mNA[39m     FALSE    [31mNA[39m  [31mNA[39m       4
[90m2[39m SRR25848â€¦ CP00â€¦ [4m2[24m[4m6[24m[4m3[24m235 [31mNA[39m    G     T        85 [31mNA[39m     FALSE    [31mNA[39m  [31mNA[39m       6
[90m3[39m SRR25848â€¦ CP00â€¦ [4m2[24m[4m8[24m[4m1[24m923 [31mNA[39m    G     T       217 [31mNA[39m     FALSE    [31mNA[39m  [31mNA[39m      10
[90m4[39m SRR25848â€¦ CP00â€¦ [4m4[24m[4m3[24m[4m3[24m359 [31mNA[39m    CTTTâ€¦ CTTTâ€¦    64 [31mNA[39m     TRUE     12   1      12
[90m5[39m SRR25848â€¦ CP00â€¦ [4m4[24m[4m7[24m[4m3[24m901 [31mNA[39m    CCGC  CCGCâ€¦   228 [31mNA[39m     TRUE      9   0.9    10
[90m6[39m SRR25848â€¦ CP00â€¦ [4m6[24m[4m4[24m[4m8[24m692 [31mNA[39m    C     T       210 [31mNA[39m     FALSE    [31mNA[39m  [31mNA[39m      10
[90m# â€¦ with 18 more variables: VDB [3m[90m<dbl>[90m[23m, RPB [3m[90m<dbl>[90m[23m, MQB [3m[90m<dbl>[90m[23m, BQB [3m[90m<dbl>[90m[23m,[39m
[90m#   MQSB [3m[90m<dbl>[90m[23m, SGB [3m[90m<dbl>[90m[23m, MQ0F [3m[90m<dbl>[90m[23m, ICB [3m[90m<lgl>[90m[23m, HOB [3m[90m<lgl>[90m[23m, AC [3m[90m<dbl>[90m[23m,[39m
[90m#   AN [3m[90m<dbl>[90m[23m, DP4 [3m[90m<chr>[90m[23m, MQ [3m[90m<dbl>[90m[23m, Indiv [3m[90m<chr>[90m[23m, gt_PL [3m[90m<dbl>[90m[23m, gt_GT [3m[90m<dbl>[90m[23m,[39m
[90m#   gt_GT_alleles [3m[90m<chr>[90m[23m, POLPROB [3m[90m<dbl>[90m[23m[39m
~~~
{: .output}

> ## Exercise
> There are a lot of columns in our dataset, so let's just look at the
> `sample_id`, `POS`, `QUAL`, and `POLPROB` columns for now. Add a 
> line to the above code to only show those columns. 
> 
>> ## Solution
>> 
>> ~~~
>> variants %>%
>>  mutate(POLPROB = 1 - 10 ^ -(QUAL/10)) %>%
>>  glimpse %>%
>>  select(sample_id, POS, QUAL, POLPROB)
>> ~~~
>> {: .language-r}
>> 
>> 
>> 
>> ~~~
>> Rows: 801
>> Columns: 30
>> $ sample_id     [3m[90m<chr>[39m[23m "SRR2584863", "SRR2584863", "SRR2584863", "SRR2584863",â€¦
>> $ CHROM         [3m[90m<chr>[39m[23m "CP000819.1", "CP000819.1", "CP000819.1", "CP000819.1",â€¦
>> $ POS           [3m[90m<dbl>[39m[23m 9972, 263235, 281923, 433359, 473901, 648692, 1331794, â€¦
>> $ ID            [3m[90m<lgl>[39m[23m NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,â€¦
>> $ REF           [3m[90m<chr>[39m[23m "T", "G", "G", "CTTTTTTT", "CCGC", "C", "C", "G", "ACAGâ€¦
>> $ ALT           [3m[90m<chr>[39m[23m "G", "T", "T", "CTTTTTTTT", "CCGCGC", "T", "A", "A", "Aâ€¦
>> $ QUAL          [3m[90m<dbl>[39m[23m 91.0000, 85.0000, 217.0000, 64.0000, 228.0000, 210.0000â€¦
>> $ FILTER        [3m[90m<lgl>[39m[23m NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,â€¦
>> $ INDEL         [3m[90m<lgl>[39m[23m FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, Tâ€¦
>> $ IDV           [3m[90m<dbl>[39m[23m NA, NA, NA, 12, 9, NA, NA, NA, 2, 7, NA, NA, NA, NA, NAâ€¦
>> $ IMF           [3m[90m<dbl>[39m[23m NA, NA, NA, 1.000000, 0.900000, NA, NA, NA, 0.666667, 1â€¦
>> $ DP            [3m[90m<dbl>[39m[23m 4, 6, 10, 12, 10, 10, 8, 11, 3, 7, 9, 20, 12, 19, 15, 1â€¦
>> $ VDB           [3m[90m<dbl>[39m[23m 0.0257451, 0.0961330, 0.7740830, 0.4777040, 0.6595050, â€¦
>> $ RPB           [3m[90m<dbl>[39m[23m NA, 1.000000, NA, NA, NA, NA, NA, NA, NA, NA, 0.900802,â€¦
>> $ MQB           [3m[90m<dbl>[39m[23m NA, 1.0000000, NA, NA, NA, NA, NA, NA, NA, NA, 0.150134â€¦
>> $ BQB           [3m[90m<dbl>[39m[23m NA, 1.000000, NA, NA, NA, NA, NA, NA, NA, NA, 0.750668,â€¦
>> $ MQSB          [3m[90m<dbl>[39m[23m NA, NA, 0.974597, 1.000000, 0.916482, 0.916482, 0.90080â€¦
>> $ SGB           [3m[90m<dbl>[39m[23m -0.556411, -0.590765, -0.662043, -0.676189, -0.662043, â€¦
>> $ MQ0F          [3m[90m<dbl>[39m[23m 0.000000, 0.166667, 0.000000, 0.000000, 0.000000, 0.000â€¦
>> $ ICB           [3m[90m<lgl>[39m[23m NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,â€¦
>> $ HOB           [3m[90m<lgl>[39m[23m NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,â€¦
>> $ AC            [3m[90m<dbl>[39m[23m 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1â€¦
>> $ AN            [3m[90m<dbl>[39m[23m 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1â€¦
>> $ DP4           [3m[90m<chr>[39m[23m "0,0,0,4", "0,1,0,5", "0,0,4,5", "0,1,3,8", "1,0,2,7", â€¦
>> $ MQ            [3m[90m<dbl>[39m[23m 60, 33, 60, 60, 60, 60, 60, 60, 60, 60, 25, 60, 10, 60,â€¦
>> $ Indiv         [3m[90m<chr>[39m[23m "/home/dcuser/dc_workshop/results/bam/SRR2584863.aligneâ€¦
>> $ gt_PL         [3m[90m<dbl>[39m[23m 1210, 1120, 2470, 910, 2550, 2400, 2080, 2550, 11128, 1â€¦
>> $ gt_GT         [3m[90m<dbl>[39m[23m 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1â€¦
>> $ gt_GT_alleles [3m[90m<chr>[39m[23m "G", "T", "T", "CTTTTTTTT", "CCGCGC", "T", "A", "A", "Aâ€¦
>> $ POLPROB       [3m[90m<dbl>[39m[23m 1.0000000, 1.0000000, 1.0000000, 0.9999996, 1.0000000, â€¦
>> ~~~
>> {: .output}
>> 
>> 
>> 
>> ~~~
>> [90m# A tibble: 801 x 4[39m
>>    sample_id      POS  QUAL POLPROB
>>    [3m[90m<chr>[39m[23m        [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m   [3m[90m<dbl>[39m[23m
>> [90m 1[39m SRR2584863    [4m9[24m972    91    1.00
>> [90m 2[39m SRR2584863  [4m2[24m[4m6[24m[4m3[24m235    85    1.00
>> [90m 3[39m SRR2584863  [4m2[24m[4m8[24m[4m1[24m923   217    1   
>> [90m 4[39m SRR2584863  [4m4[24m[4m3[24m[4m3[24m359    64    1.00
>> [90m 5[39m SRR2584863  [4m4[24m[4m7[24m[4m3[24m901   228    1   
>> [90m 6[39m SRR2584863  [4m6[24m[4m4[24m[4m8[24m692   210    1   
>> [90m 7[39m SRR2584863 1[4m3[24m[4m3[24m[4m1[24m794   178    1   
>> [90m 8[39m SRR2584863 1[4m7[24m[4m3[24m[4m3[24m343   225    1   
>> [90m 9[39m SRR2584863 2[4m1[24m[4m0[24m[4m3[24m887    56    1.00
>> [90m10[39m SRR2584863 2[4m3[24m[4m3[24m[4m3[24m538   167    1   
>> [90m# â€¦ with 791 more rows[39m
>> ~~~
>> {: .output}
> {: .solution}
{: .challenge}

### Split-apply-combine data analysis and the summarize() function

Many data analysis tasks can be approached using the "split-apply-combine"
paradigm: split the data into groups, apply some analysis to each group, and
then combine the results. `dplyr` makes this very easy through the use of the
`group_by()` function, which splits the data into groups. When the data is
grouped in this way `summarize()` can be used to collapse each group into
a single-row summary. `summarize()` does this by applying an aggregating
or summary function to each group. For example, if we wanted to group
by sample_id and find the number of rows of data for each 
sample, we would do:


~~~
variants %>%
  group_by(sample_id) %>%
  summarize(n())
~~~
{: .language-r}



~~~
[90m# A tibble: 3 x 2[39m
  sample_id  `n()`
  [3m[90m<chr>[39m[23m      [3m[90m<int>[39m[23m
[90m1[39m SRR2584863    25
[90m2[39m SRR2584866   766
[90m3[39m SRR2589044    10
~~~
{: .output}

It can be a bit tricky at first, but we can imagine physically splitting the data 
frame by groups and applying a certain function to summarize the data.

<center>
<img src="../fig/split_apply_combine.png" alt="rstudio default session" style="width: 500px;"/>
</center>
^[This figure was adapted from the Software Carpentry lesson, [R for Reproducible Scientific Analysis](https://swcarpentry.github.io/r-novice-gapminder/13-dplyr/)]

Here the summary function used was `n()` to find the count for each
group. Since this is a quite a common operation, there is a simpler method 
called `tally()`:


~~~
variants %>%
  group_by(sample_id) %>%
  tally()
~~~
{: .language-r}



~~~
[90m# A tibble: 3 x 2[39m
  sample_id      n
  [3m[90m<chr>[39m[23m      [3m[90m<int>[39m[23m
[90m1[39m SRR2584863    25
[90m2[39m SRR2584866   766
[90m3[39m SRR2589044    10
~~~
{: .output}

We can also apply many other functions to individual columns to get other 
summary statistics. For example,we can use built-in functions like `mean()`, 
`median()`, `min()`, and `max()`. These are called "built-in functions" because 
they come with R and don't require that you install any additional packages. 
By default, all **R functions operating on vectors that contains missing data will return NA**.
It's a way to make sure that users know they have missing data, and make a 
conscious decision on how to deal with it. When dealing with simple statistics 
like the mean, the easiest way to ignore `NA` (the missing data) is 
to use `na.rm = TRUE` (`rm` stands for remove). 

So to view the highest filtered depth (`DP`) for each sample:


~~~
variants %>%
  group_by(sample_id) %>%
  summarize(max(DP))
~~~
{: .language-r}



~~~
[90m# A tibble: 3 x 2[39m
  sample_id  `max(DP)`
  [3m[90m<chr>[39m[23m          [3m[90m<dbl>[39m[23m
[90m1[39m SRR2584863        20
[90m2[39m SRR2584866        79
[90m3[39m SRR2589044        16
~~~
{: .output}

<!-- You can group by multiple columns too. For example, we might want to  -->
<!-- know if ...  -->

<!-- ```{r, purl = FALSE} -->

<!-- ``` -->

<!-- You can also summarize multiple variables at the same time. Let's -->
<!-- count how many samples we have in each group using the `n()` function: -->

<!-- ```{r, purl = FALSE} -->

<!-- ``` -->

[Handy dplyr cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf)

^[Much of this lesson was copied or adapted from Jeff Hollister's [materials](http://usepa.github.io/introR/2015/01/14/03-Clean/)]
